{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMSR Systems, lab 1: basics of JPEG compression\n",
    "\n",
    "Today, we are going to look more closely at some building blocks in JPEG compression. More specifically, we will apply the DCT to macroblocks in images, use quantization (and optionally subsampling) to reduce the amount of relevant information to be 'encoded' back, and then 'decode' back to examine results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to hand in\n",
    "As final deliverable to demonstrate your successful completion of this assignment, please submit a file named [studentNumberMember1_studentNumberMember2.pdf] through Brightspace.\n",
    "\n",
    "This file should:\n",
    "* Two decoded results of the (padded) Lena image with different configurations from the example given below. In terms of 'different configurations', at least change the quantization matrix weights, and include the adjusted matrices in your report. Besides this, you are free to also adjust subsampling techniques or macroblock sizes.\n",
    "* Two decoded results on an image of your own choice. You are free to reuse the configurations you took for the Lena image. Again, make sure to include quantization matrices and other relevant configuration parameter details in your report.\n",
    "* With these results and configurations, include a short discussion and explanation on the main differences between decoded results.\n",
    "\n",
    "Further instructions can be found further down this notebook, at the point where we give an example plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "First, we will import relevant libraries again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request as ur\n",
    "\n",
    "import cv2\n",
    "\n",
    "from cvtools import ipynb_show_cv2_image\n",
    "from cvtools import ipynb_show_matrix\n",
    "from datasets import CS4065_Dataset\n",
    "\n",
    "# Don't forget to include this line (only working for iPython notebooks) to use inline plots.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better feel of image sizes, we create a helper function that exposes size parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_numpy_image_size(image_size):\n",
    "  \"\"\"\n",
    "  Usage:\n",
    "    height, width, channels = parse_numpy_image_size(np.shape(image))\n",
    "  \"\"\"\n",
    "  try:\n",
    "    height, width, channels = image_size\n",
    "  except:\n",
    "    height, width = image_size\n",
    "    channels = 1\n",
    "  return height, width, channels\n",
    "\n",
    "\n",
    "def format_image_size(image_size):\n",
    "  \"\"\"\n",
    "  Usage:\n",
    "    formatted_image_size = format_image_size(np.shape(image))\n",
    "  \"\"\"\n",
    "  height, width, channels = parse_numpy_image_size(image_size)\n",
    "  return '%d x %d (%d channels)' % (width, height, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read an image (the Lena image), which already should have been pulled automatically into your data folder through Git when you ran the test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to override the location where the dataset is stored (because you are not using the VM) \n",
    "# input the path as follows:\n",
    "# cs4065_dataset = CS4065_Dataset(os.path.join(...))\n",
    "\n",
    "cs4065_dataset = CS4065_Dataset()\n",
    "\n",
    "lena_image_path = cs4065_dataset.get_testcases_data()['image']\n",
    "lena_image_original = cv2.imread(lena_image_path)\n",
    "lena_image_original_size = np.shape(lena_image_original)\n",
    "\n",
    "# What are the dimensions of this image?\n",
    "print('original image size: {}'.format(format_image_size(lena_image_original_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use square macroblocks for DCT analysis. Let's set it to the default 8x8 size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set macroblocks size.\n",
    "MACROBLOCK_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling differently-sized images\n",
    "The Lena image is 512 x 512 pixels, and as such, an integer amount of 8x8 macroblocks can exactly fit in.\n",
    "\n",
    "However, if you will use your own images later on, they might not have such nice dimensions.<br/>\n",
    "To handle this, we first do a small sub-exercise to ensure an integer amount of macroblocks can be used.\n",
    "\n",
    "For this, we slightly modify the Lena image by slightly cutting of a part from the right, top and bottom of the original image.\n",
    "\n",
    "Then, we will make sure this image still fits in a grid of full macroblocks. For doing this, we determine how wide and tall the image should be to fit an integer amount of macroblocks. We then will apply padding to the image: adding black pixels to the bottom and right side, such that the padded image will allow for an integer amount of macroblocks to be used.<br/>\n",
    "**Use the padded image resulting from this exercise as the basis of the examples on the Lena picture in your lab report.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, crop the image (you will pad it in the next cell).\n",
    "lena_image_cropped = lena_image_original[:-5, 15:-14, :]\n",
    "lena_image_cropped_size = np.shape(lena_image_cropped)\n",
    "\n",
    "print('cropped image size: {}'.format(format_image_size(lena_image_cropped_size)))\n",
    "ipynb_show_cv2_image(lena_image_cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "Complete the <code>pad_image()</code> function below, to extend a picture of any size such that an integer amount of macroblocks fit in. Note that we set <code>MACROBLOCK_SIZE</code> to 8x8 pixels, but you can flexibly update this parameter to try other block sizes. Complete the function such that any specified macroblock size can be accommodated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the image so that each side is a multiple integer of the macroblock size.\n",
    "\n",
    "def pad_image(image, block_size = MACROBLOCK_SIZE):  \n",
    "  height, width, channels = parse_numpy_image_size(np.shape(image))\n",
    "\n",
    "  # TODO: replace '0' in the following two lines,\n",
    "  # such that an integer amount of macroblocks can be used in terms of width and length of an extended (padded) image.\n",
    "  padded_height = 0 # replace this value\n",
    "  padded_width = 0 # replace this value\n",
    "\n",
    "  # assertion check: will not pass if padded_height is smaller than the original picture height,\n",
    "  # and padded_width is smaller than the original picture width\n",
    "  assert padded_height >= height and padded_width >= width, (\n",
    "      (padded_height, height), (padded_width, width))\n",
    "\n",
    "  padded_image = np.zeros((padded_height, padded_width, channels), dtype=np.uint8)\n",
    "  padded_image[:height, :width, :] = image\n",
    "  return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lena_image = pad_image(lena_image_cropped)\n",
    "lena_image_size = np.shape(lena_image)\n",
    "\n",
    "print('cropped image size before padding: {}'.format(format_image_size(np.shape(lena_image_cropped))))\n",
    "print('image size after padding: {}'.format(format_image_size(np.shape(lena_image))))\n",
    "\n",
    "# Use this as a checkpoint to verify that you padded correctly.\n",
    "lena_image_width, lena_image_height, _ = parse_numpy_image_size(lena_image_size)\n",
    "assert 0 == lena_image_width % MACROBLOCK_SIZE and 0 == lena_image_height % MACROBLOCK_SIZE\n",
    "\n",
    "ipynb_show_cv2_image(lena_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel and macroblock coordinates\n",
    "We will work with two different indexing mechanisms now: the indices of individual pixels, but also the indices of macroblocks.<br/>\n",
    "We need to add some code to know what pixels in our image belong to what macroblock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "Given an image, or more in general a (subsampled) channel of an image, we want to know how many macroblocks it has.\n",
    "For this, we use a function called <code>get_number_of_macroblocks()</code>. You can either use the current implementation of <code>get_number_of_macroblocks()</code> and modify <code>_macroblock_index()</code> or, if you prefer, rewrite <code>get_number_of_macroblocks()</code> from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_macroblock_coords(coords, block_size = MACROBLOCK_SIZE):\n",
    "  x, y = coords\n",
    "    \n",
    "  \"\"\"Computes the macroblock coordinates of a pixel given the (square) block size.\"\"\"\n",
    "  def _macroblock_index(pos):\n",
    "    # This is the core function that does the job for get_number_of_macroblocks().\n",
    "    # TODO: complete the line below.\n",
    "    return 0\n",
    "  return (_macroblock_index(x), _macroblock_index(y))\n",
    "\n",
    "\n",
    "def get_number_of_macroblocks(image_size, block_size = MACROBLOCK_SIZE):\n",
    "  \"\"\"Returns the number of horizontal and vertical macroblocks.\"\"\"\n",
    "  return get_macroblock_coords((image_size[1], image_size[0]), block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macroblock (0,0).\n",
    "print(get_macroblock_coords((0, 0)))\n",
    "print(get_macroblock_coords((0, 7)))\n",
    "print(get_macroblock_coords((7, 7)))\n",
    "print(get_macroblock_coords((7, 0)))\n",
    "\n",
    "# Macroblocks adjacent to (0,0).\n",
    "print(get_macroblock_coords((8, 0)))\n",
    "print(get_macroblock_coords((0, 8)))\n",
    "print(get_macroblock_coords((8, 8)))\n",
    "\n",
    "print('image size: {}'.format(format_image_size(lena_image_size)))\n",
    "print('number of macroblocks: {} horizontal and {} vertical'.format(*get_number_of_macroblocks(lena_image_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "You also need to implement <code>macroblock_coords_to_pixel_vertices()</code>, the function that tells us what region of the image is covered by a macroblock.\n",
    "The output can be encoded as opposite pixel vertex coordinates of the square region in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macroblock_coords_to_pixel_vertices(macroblock_coords, block_size = MACROBLOCK_SIZE):\n",
    "  \"\"\"Maps a macroblock onto pixel vertex coordinates.\"\"\"\n",
    "  # TODO: complete the four lines below.\n",
    "  x0 = 0\n",
    "  y0 = 0\n",
    "  x1 = 0\n",
    "  y1 = 0\n",
    "  return (x0, y0), (x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test your function with the top-left macroblock.\n",
    "(x0, y0), (x1, y1) = macroblock_coords_to_pixel_vertices((0, 0))\n",
    "assert x0 == y0 == 0 and x1 == y1 == MACROBLOCK_SIZE - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visually check that everything works.\n",
    "Let's draw a macroblock of a random pixel to check that the output of your functions makes sense.<br/>\n",
    "Run the cell below multiple times to see the result on different points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize a macroblock of a random pixel in the image.\n",
    "# For a better visualization, we temporarily use bigger macroblocks.\n",
    "BIGGER_MACROBLOCK_SIZE = 32\n",
    "\n",
    "def get_random_pixel_coords(image_size):\n",
    "  \"\"\"Returns random (x, y) coordinates given the image size.\"\"\"\n",
    "  return (np.uint16(np.random.randint(0, image_size[1])),\n",
    "          np.uint16(np.random.randint(0, image_size[0])))\n",
    "\n",
    "\n",
    "# Get a random pixel.\n",
    "pixel_coords = get_random_pixel_coords(lena_image_size)\n",
    "print('pixel coordinates', pixel_coords)\n",
    "\n",
    "# Get its macroblock coordinates.\n",
    "macroblock_coords = get_macroblock_coords(pixel_coords, BIGGER_MACROBLOCK_SIZE)\n",
    "print('macroblock coordinates', macroblock_coords)\n",
    "\n",
    "# Visualize colored annotations on a gray scale copy of the original image.\n",
    "lena_image_with_macroblock = cv2.cvtColor(\n",
    "    cv2.cvtColor(lena_image, cv2.COLOR_BGR2GRAY), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Get the top-left and bottom-right vertex coordinates to draw the macroblock.\n",
    "(rect_pt1, rect_pt2) = macroblock_coords_to_pixel_vertices(macroblock_coords, BIGGER_MACROBLOCK_SIZE)\n",
    "cv2.rectangle(lena_image_with_macroblock, rect_pt1, rect_pt2, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "# Draw the pixel.\n",
    "cv2.circle(lena_image_with_macroblock, pixel_coords, 2, (0, 0, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "# Show the image.\n",
    "ipynb_show_cv2_image(lena_image_with_macroblock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPEG image compression\n",
    "We now will move towards actual compression techniques.\n",
    "\n",
    "### First step: subsample the YUV channels.\n",
    "As mentioned in the lecture, JPEG uses the YUV color coordinates, also known as YCbCr (considering chrominance and luminance).<br/>\n",
    "Luminance is more differentiating than chrominance, so we don't use all chrominance values but average and subsample them (think of the 4:2:2 example in the lecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (explained below when used for the first time).\n",
    "USE_ANTIALIASING_FILTER = True\n",
    "FILTER_SIZE = (2, 2)\n",
    "SUBSAMPLING_FACTORS = (2, 2)  # Vertical and horizontal.\n",
    "\n",
    "def subsample_chrominance_channels(image):\n",
    "  # Let's convert the RGB image to the YUV space.\n",
    "  # You will apply compression in such color space.\n",
    "  image_YCrCb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "  # Anti-aliasing filter.\n",
    "  # Before we subsample the Cr and Cb channels, we apply an averaging filter to avoid artifacts.\n",
    "  # We use cv2.boxFilter() for this (see http://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#boxfilter).\n",
    "  if USE_ANTIALIASING_FILTER:\n",
    "    image_Cr_channel_filtered = cv2.boxFilter(image_YCrCb[:,:,1], ddepth=-1, ksize=FILTER_SIZE)\n",
    "    image_Cb_channel_filtered = cv2.boxFilter(image_YCrCb[:,:,2], ddepth=-1, ksize=FILTER_SIZE)\n",
    "  else:\n",
    "    image_Cr_channel_filtered = image_YCrCb[:,:,1]\n",
    "    image_Cb_channel_filtered = image_YCrCb[:,:,2]\n",
    "\n",
    "  # Subsampling step: we will skip crominance values (similar to image resizing).\n",
    "  # We use numpy array slicing (see http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html).\n",
    "  image_Cr_channel_subsampled = image_Cr_channel_filtered[\n",
    "      ::SUBSAMPLING_FACTORS[0], ::SUBSAMPLING_FACTORS[1]]\n",
    "  image_Cb_channel_subsampled = image_Cb_channel_filtered[\n",
    "      ::SUBSAMPLING_FACTORS[0], ::SUBSAMPLING_FACTORS[1]]\n",
    "\n",
    "  return [\n",
    "      image_YCrCb[:,:,0],  # We don't toch the luminance channel.\n",
    "      image_Cr_channel_subsampled,\n",
    "      image_Cb_channel_subsampled\n",
    "  ]\n",
    "\n",
    "\n",
    "lena_image_YCrCb_subsampled = subsample_chrominance_channels(lena_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "Subsampling effectively means we are looking at larger, rougher analysis blocks. Also note that the macroblock size does not change, even when a channel is subsampled.\n",
    "\n",
    "Continue this lab until you have compressed the image with chrominance subsampling - i.e., using <code>subsample_chrominance_channels()</code>. Then come back here, replace <code>lena_image_YCrCb_subsampled</code> with the YCrCb image and recompress the image.\n",
    "Make sure that you still have a visible copy of the previously compressed image.\n",
    "\n",
    "**Can you notice differences in visual quality?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second step: define the quantization tables.\n",
    "Define the quantization tables to use. For now, we will use default values from the original JPEG specification document, looking at 8x8 macroblocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luminance and chrominance quantization tables.\n",
    "# (from Annex K of https://www.w3.org/Graphics/JPEG/itu-t81.pdf).\n",
    "\n",
    "def parse_quantization_table(data):\n",
    "  return np.array([[\n",
    "      np.float64(cell) for cell in row.split(' ')] for row in (\n",
    "          data.split('\\n'))], dtype=np.float64)\n",
    "\n",
    "\n",
    "# Quantization table to be used on the Y channel.\n",
    "JPEG_STANDARD_LUMINANCE_QUANTIZATION_TABLE = parse_quantization_table(\n",
    "\"\"\"16 11 10 16 24 40 51 61\n",
    "12 12 14 19 26 58 60 55\n",
    "14 13 16 24 40 57 69 56\n",
    "14 17 22 29 51 87 80 62\n",
    "18 22 37 56 68 109 103 77\n",
    "24 35 55 64 81 104 113 92\n",
    "49 64 78 87 103 121 120 101\n",
    "72 92 95 98 112 100 103 99\"\"\")\n",
    "\n",
    "# Quantization table to be used on the Cr and Cb channels.\n",
    "JPEG_STANDARD_CHROMINANCE_QUANTIZATION_TABLE = parse_quantization_table(\n",
    "\"\"\"17 18 24 47 99 99 99 99\n",
    "18 21 26 66 99 99 99 99\n",
    "24 26 56 99 99 99 99 99\n",
    "47 66 99 99 99 99 99 99\n",
    "99 99 99 99 99 99 99 99\n",
    "99 99 99 99 99 99 99 99\n",
    "99 99 99 99 99 99 99 99\n",
    "99 99 99 99 99 99 99 99\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's put together the quantization tables of each channel.\n",
    "quantization_tables = [\n",
    "    JPEG_STANDARD_LUMINANCE_QUANTIZATION_TABLE,  # Y channel.\n",
    "    JPEG_STANDARD_CHROMINANCE_QUANTIZATION_TABLE,  # Cr channel.\n",
    "    JPEG_STANDARD_CHROMINANCE_QUANTIZATION_TABLE,  # Cb channel.\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third step: DCT coefficients quantization.\n",
    "We will use DCT of 8x8 blocks and quantize the coefficients on the luminance (Y) and chrominance (Cr and Cb) channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "First, have a look at how <code>quantize_image_YCrCb_dct()</code> (two cells below) is implemented. This function contains the main loop: each block in each channel is indepently compressed via <code>quantizemacroblock_dct</code>.\n",
    "\n",
    "Your task is implementing <code>quantizemacroblock_dct()</code> in the cell below. Read the comments in the inline doc to correctly use the passed quantization table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizemacroblock_dct(macroblock, quantization_table):\n",
    "  \"\"\"\n",
    "  Quantize DCT coefficients of a macroblock given a quantization table.\n",
    "  \n",
    "  DCT coefficients are real values.\n",
    "  We first scale them (the larger the coefficients in the quantization table,\n",
    "  the smaller will be the scaled values).\n",
    "  Finally, we round off the scaled values in order to approximate each coefficient\n",
    "  to an integer value (quantization process).\n",
    "  \n",
    "  The quantized DCT coefficients will be used with loss-less compression techniques\n",
    "  in order to store them efficiently.\n",
    "  \"\"\"\n",
    "  assert np.shape(macroblock) == np.shape(quantization_table), (\n",
    "      np.shape(macroblock), np.shape(quantization_table))\n",
    "  \n",
    "  macroblock_dct = cv2.dct(macroblock)\n",
    "  \n",
    "  # TODO: give quantized_macroblock_dct the value it should have\n",
    "  # this is not correct, replace 'macroblock_dct' by proper quantization\n",
    "  quantized_macroblock_dct = macroblock_dct\n",
    "\n",
    "  return quantized_macroblock_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main loop for applying quantization in a full image\n",
    "def quantize_image_YCrCb_dct(\n",
    "    image_YCrCb_subsampled, scaled_quantization_tables, image_size, bln_verbose = True):\n",
    "  if bln_verbose:\n",
    "    def _vprint(what):\n",
    "      print(what)\n",
    "  else:\n",
    "    def _vprint(what):\n",
    "      pass\n",
    "  _vprint('Quantizing DCT coefficients')\n",
    "\n",
    "  # Initialization and parameters.  \n",
    "  image_YCrCb_dct_quantized = []\n",
    "  block_size = MACROBLOCK_SIZE\n",
    "\n",
    "  # Each channel is independently processed.\n",
    "  for channel_index, (channel, quantization_table) in enumerate(\n",
    "      zip(image_YCrCb_subsampled, scaled_quantization_tables)):\n",
    "\n",
    "    # Channel properties.\n",
    "    channel_size = np.shape(channel)\n",
    "    number_of_horizontal_macroblocks, number_of_vertical_macroblocks = (\n",
    "        get_number_of_macroblocks(channel_size, block_size))\n",
    "    quantization_table_data_type = quantization_table.dtype\n",
    "\n",
    "    _vprint('. channel #%d' % channel_index)\n",
    "    _vprint('  channel size: %s' % format_image_size(channel_size))\n",
    "    _vprint('  number of macroblocks: %d x %d' % (\n",
    "        number_of_horizontal_macroblocks, number_of_vertical_macroblocks))\n",
    "\n",
    "    # Initialize quantized channel matrix.\n",
    "    channel_dct_quantized = np.zeros(channel_size, dtype=quantization_table_data_type)\n",
    "    \n",
    "    # Each macroblock is independently quantized.\n",
    "    for row in range(number_of_vertical_macroblocks):\n",
    "      for column in range(number_of_horizontal_macroblocks):\n",
    "        # Extract the macroblock from the channel matrix.\n",
    "        (left_top, right_bottom) = macroblock_coords_to_pixel_vertices((column, row), block_size)\n",
    "        macroblock = channel[left_top[1]:right_bottom[1]+1, left_top[0]:right_bottom[0]+1]\n",
    "\n",
    "        # Compute and quantize DCT coefficients.\n",
    "        macroblock_dct_quantized = quantizemacroblock_dct(\n",
    "            macroblock.astype(quantization_table_data_type), quantization_table)\n",
    "\n",
    "        # Copy macroblock data.\n",
    "        channel_dct_quantized[\n",
    "            left_top[1]:right_bottom[1]+1, left_top[0]:right_bottom[0]+1] = (\n",
    "                macroblock_dct_quantized)\n",
    "\n",
    "    _vprint('  quantized DCT coefficients matrix size: %d x %d' % np.shape(channel_dct_quantized))\n",
    "    image_YCrCb_dct_quantized.append(channel_dct_quantized)\n",
    "\n",
    "  return image_YCrCb_dct_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try the quantization on the Lena image\n",
    "lena_image_YCrCb_dct_quantized = quantize_image_YCrCb_dct(\n",
    "    lena_image_YCrCb_subsampled, quantization_tables, lena_image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth step: decoding the quantized DCT coefficients.\n",
    "As discussed in the lecture, the quantized DCT values would still be compressed further by applying lossless compression techniques. We will not do that in this lab. However, we will look at what happens when we take these quantized values, and try to reconstruct an image from them. To reconstruct the image, we need to map the quantized coefficients back to the YUV space (via IDCT and the quantization table) and then convert the decoded image to RGB (for visualization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "Similarly as done for <code>quantize_image_YCrCb_dct()</code>, complete <code>decode_quantized_dct_block()</code>. Also in this case, start by first checking how the main decompression loop has been implemented in <code>decode_image_YCrCb_dct_quantized()</code>, two blocks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_quantized_dct_block(macroblock_dct_quantized, quantization_table):\n",
    "  \"\"\"\n",
    "  Decode quantized DCT coefficients given the quantization table used at the encoding step.\n",
    "\n",
    "  This function is dual to quantizemacroblock_dct().\n",
    "  DCT coefficients can be negative, we need to map the macroblock values in the range [0, 255].\n",
    "  \"\"\"\n",
    "  # TODO: change the line below accordingly to your changes in quantizemacroblock_dct().\n",
    "  macroblock_decoded = cv2.idct(macroblock_dct_quantized)\n",
    "  return np.clip(macroblock_decoded, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image_YCrCb_dct_quantized(image_YCrCb_dct_quantized, scaled_quantization_tables,\n",
    "                                     image_size, block_size = MACROBLOCK_SIZE, bln_verbose = True):\n",
    "  if bln_verbose:\n",
    "    def _vprint(what):\n",
    "      print(what)\n",
    "  else:\n",
    "    def _vprint(what):\n",
    "      pass\n",
    "  _vprint('Decoding quantized DCT')\n",
    "  pass\n",
    "\n",
    "  image_height = image_size[0]\n",
    "  image_width = image_size[1]\n",
    "  number_of_channels = image_size[2]\n",
    "\n",
    "  image_YCrCb_decoded = np.zeros(image_size, dtype=np.uint8)\n",
    "  _vprint('. decoded image size: %d x %d' % (image_width, image_height))\n",
    "    \n",
    "  for channel_index, (channel_dct_quantized, quantization_table) in enumerate(\n",
    "      zip(image_YCrCb_dct_quantized, scaled_quantization_tables)):\n",
    "    # Channel properties.\n",
    "    channel_size = np.shape(channel_dct_quantized)\n",
    "    number_of_horizontal_macroblocks, number_of_vertical_macroblocks = (\n",
    "        get_number_of_macroblocks(channel_size, block_size))\n",
    "\n",
    "    _vprint('. channel #%d' % channel_index)\n",
    "    _vprint('  channel size: %s' % format_image_size(channel_size))\n",
    "    _vprint('  number of macroblocks: %d x %d' % (\n",
    "        number_of_horizontal_macroblocks, number_of_vertical_macroblocks))\n",
    "\n",
    "    # Initialize the decoded channel matrix.\n",
    "    decoded_channel = np.zeros(channel_size, dtype=channel_dct_quantized.dtype)\n",
    "    \n",
    "    # Each macroblock is independently decoded.\n",
    "    for row in range(number_of_vertical_macroblocks):\n",
    "      for column in range(number_of_horizontal_macroblocks):\n",
    "        # Extract the macroblock from the quantized DCT coefficients matrix.\n",
    "        (left_top, right_bottom) = macroblock_coords_to_pixel_vertices((column, row), block_size)\n",
    "        macroblock_dct_quantized = channel_dct_quantized[\n",
    "            left_top[1]:right_bottom[1]+1, left_top[0]:right_bottom[0]+1]\n",
    "\n",
    "        # Decode quantized DCT coefficients.\n",
    "        macroblock_decoded = decode_quantized_dct_block(\n",
    "            macroblock_dct_quantized, quantization_table)\n",
    "\n",
    "        # Copy macroblock decoded data.\n",
    "        decoded_channel[\n",
    "            left_top[1]:right_bottom[1]+1, left_top[0]:right_bottom[0]+1] = macroblock_decoded\n",
    "\n",
    "    # Resize the decoded channel matrix.\n",
    "    image_YCrCb_decoded[:, :, channel_index] = cv2.resize(decoded_channel, (image_width, image_height))\n",
    "\n",
    "  return image_YCrCb_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, convertYUV to RGB and compare the original and compressed image.\n",
    "lena_image_YCrCb_decoded = decode_image_YCrCb_dct_quantized(\n",
    "    lena_image_YCrCb_dct_quantized, quantization_tables, lena_image_size)\n",
    "lena_image_BGR_decoded = cv2.cvtColor(lena_image_YCrCb_decoded, cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "ipynb_show_cv2_image(lena_image, 'original')\n",
    "ipynb_show_cv2_image(lena_image_BGR_decoded, 'compressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the differences in each channel.\n",
    "# below a helper function to show differences in a matrix\n",
    "def show_image_differences(image0, image1):\n",
    "  number_of_channels = np.shape(image0)[2]\n",
    "\n",
    "  for channel_index in range(number_of_channels):\n",
    "    error = np.abs(\n",
    "        image0[:,:,channel_index] - image1[:,:,channel_index])\n",
    "    title = 'error in channel #%d (min: %d, avg: %.1f, max: %d)' % (\n",
    "        channel_index, np.min(error), np.average(error), np.max(error))\n",
    "    print(title)\n",
    "    ipynb_show_matrix(error, title)\n",
    "\n",
    "# and here is how to call the function\n",
    "show_image_differences(lena_image, lena_image_BGR_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, experiment with the effect of quantization matrices.\n",
    "Experiment with different values in the luminance and chrominance quantization tables (e.g., try to scale all the values), and discuss effects on the decoded result. Besides this, you are free to also adjust channel subsampling techniques or macroblock sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with Lena's portrait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_image_path = cs4065_dataset.get_testcases_data()['image']\n",
    "given_image = cv2.imread(given_image_path)\n",
    "ipynb_show_cv2_image(given_image, 'given image')\n",
    "# use the functions you used above, and use custom-defined quantization tables,\n",
    "# to experiment with the effect of different parameter settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now use an image of your choice!\n",
    "Also try out compression on an image of your choice. For this, you need the helper function below, and you can call this with an URL as showed in the cell underneath the helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "  temp_file_path, _ = ur.urlretrieve(url)\n",
    "  return temp_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of how to download and load an image from the Internet.\n",
    "image_url = 'https://upload.wikimedia.org/wikipedia/commons/2/2b/Jupiter_and_its_shrunken_Great_Red_Spot.jpg'\n",
    "self_contributed_image_path = download_file(image_url)\n",
    "self_contributed_image = cv2.imread(self_contributed_image_path)\n",
    "ipynb_show_cv2_image(self_contributed_image, 'self contributed image')\n",
    "\n",
    "# also experiment with compression effects on this image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your assignment\n",
    "\n",
    "To demonstrate you passed this assignment, please submit a pdf on Brightspace in which you include and discuss the following:\n",
    "* Two decoded results of the (padded) Lena image with different configurations from the example given below. In terms of 'different configurations', at least change the quantization matrix weights, and include the adjusted matrices in your report. Besides this, you are free to also adjust subsampling techniques or macroblock sizes.\n",
    "* Two decoded results on an image of your own choice. You are free to reuse the configurations you took for the Lena image. Again, make sure to include quantization matrices and other relevant configuration parameter details in your report.\n",
    "* With these results and configurations, include a short discussion and explanation on the main differences between decoded results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmsr",
   "language": "python",
   "name": "mmsr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
